{"version":3,"sources":["asteria42/Table.tsx","asteria42/Form.tsx","diffable/expression.ts","diffable/variable.ts","diffable/operations.ts","neuro/parameters.ts","neuro/neurons.ts","neuro/layers.ts","neuro/network.ts","neuro/activation.ts","neuro/error.ts","asteria42/Network42.ts","asteria42/Asteria42.tsx","App.tsx","index.tsx"],"names":["TableHeader","TableBody","props","rows","data","map","row","index","m","b","r","key","reverse","Table","Form","state","handleSubmit","handleChange","event","target","name","value","setState","submitForm","samples","sensitivity","generations","this","type","isFinite","min","onChange","onClick","Component","Expression","_value","NaN","_deriv","Map","valueImpl","v","has","set","derivImpl","get","clear","ExprUnary","arg","ExprBinary","left","right","ExprVariadic","terms","Variable","val","BinProduct","deriv","print","VarSum","reduce","acc","t","join","Parameter","adjustments","error","push","studyImpl","length","adjustment","learnImpl","Weight","n","w","count","bind","reset","Bias","Neuron","InputNeuron","x","TrainableNeuron","Act","weights","bias","sum","exp","neurons","p","c","getExpr","parentIndex","forEach","study","learn","HiddenNeuron","OutputNeuron","Err","y","err","getErr","Layer","InputLayer","names","Array","from","values","node","vals","TrainableLayer","HiddenLayer","parent","size","i","childIndex","getWeight","getBias","OutputLayer","childName","Network","inputLayer","hiddenLayers","outputLayer","source","input","output","inputNames","keys","outputNames","last","hiddenSizes","layer","ActivationSoftplus","Math","log","df","ErrorSquared","diff","Network42","random","Neuro","getOutputLayer","getOutput","Asteria42","net","train","undefined","rsq","sqrt","className","readOnly","App","to","path","ReactDOM","render","document","getElementById"],"mappings":"8OAQA,SAASA,IACL,OACE,+BACE,4BACE,iCACA,iCACA,iCACA,mCAMV,SAASC,EAAUC,GACf,IAAMC,EAAOD,EAAME,KAAKC,KAAI,SAACC,EAAeC,GAAmB,IACnDC,EAAYF,EAAZE,EAAGC,EAASH,EAATG,EAAGC,EAAMJ,EAANI,EACd,OACE,wBAAIC,IAAKJ,GACP,4BAAKA,GACL,mCAAKC,QAAL,IAAKA,IAAK,IACV,mCAAKC,QAAL,IAAKA,IAAK,IACV,mCAAKC,QAAL,IAAKA,IAAK,QAGfE,UACH,OACI,+BAAQT,GAcDU,MAVf,SAAeX,GAA8B,IACjCE,EAASF,EAATE,KACR,OACE,+BACE,kBAACJ,EAAD,MACA,kBAACC,EAAD,CAAWG,KAAMA,MCwBVU,E,YAnDX,WAAYZ,GAAmB,IAAD,8BAC1B,4CAAMA,KAJVa,WAG8B,IAF9BC,kBAE8B,IAM9BC,aAAe,SAACC,GAAoD,IAAD,EACvCA,EAAMC,OAAtBC,EADuD,EACvDA,KAAMC,EADiD,EACjDA,MACd,EAAKC,SAAL,eAAiBF,EAAOC,KARE,EAW9BE,WAAa,WACR,EAAKrB,MAAcc,aAAa,EAAKD,QAVtC,EAAKA,MAAQ,CAAES,QAAS,EAAGC,YAAa,EAAGC,YAAa,GACxD,EAAKV,aAAgBd,EAAcc,aAHT,E,sEAepB,IAAD,EACyCW,KAAKZ,MAA3CS,EADH,EACGA,QAASC,EADZ,EACYA,YAAaC,EADzB,EACyBA,YAC9B,OACE,8BACE,0CACA,2BACEE,KAAK,SACLR,KAAK,UACLC,MAAOQ,SAASL,GAAWA,EAAU,GACrCM,IAAI,IACJC,SAAUJ,KAAKV,eACjB,6BAEA,8CACA,2BACEW,KAAK,SACLR,KAAK,cACLC,MAAOQ,SAASJ,GAAeA,EAAc,GAC7CM,SAAUJ,KAAKV,eACjB,6BAEA,8CACA,2BACEW,KAAK,SACLR,KAAK,cACLC,MAAOQ,SAASH,GAAeA,EAAc,GAC7CI,IAAI,IACJC,SAAUJ,KAAKV,eACjB,6BAEA,2BAAOW,KAAK,SAASP,MAAM,QAAQW,QAASL,KAAKJ,kB,GAjD1CU,a,gCCTJC,E,iDACHC,OAAiBC,I,KASjBC,OAAS,IAAIC,I,oDAJjB,OAHKT,SAASF,KAAKQ,UACfR,KAAKQ,OAASR,KAAKY,aAEhBZ,KAAKQ,S,4BAKVK,GAIF,OAHKb,KAAKU,OAAOI,IAAID,IACjBb,KAAKU,OAAOK,IAAIF,EAAGb,KAAKgB,UAAUH,IAE/Bb,KAAKU,OAAOO,IAAIJ,K,8BAOvBb,KAAKQ,OAASC,IACdT,KAAKU,OAAOQ,Y,KAILC,E,YAGX,WAAYC,GAAsB,IAAD,8BAC7B,+CAHMA,SAEuB,EAE7B,EAAKA,IAAMA,EAFkB,E,2BAHJb,GASlBc,E,YAIX,WAAYC,EAAsBC,GAAwB,IAAD,8BACrD,+CAJMD,UAG+C,IAF/CC,WAE+C,EAErD,EAAKD,KAAOA,EACZ,EAAKC,MAAQA,EAHwC,E,2BAJ3BhB,GAWnBiB,E,YAGX,aAAyC,IAAD,uBACpC,+CAHMC,WAE8B,6BAAzBA,EAAyB,yBAAzBA,EAAyB,uBAEpC,EAAKA,MAAQA,EAFuB,E,2BAHRlB,GC/BrBmB,E,WAbX,WAAYjC,GAAgC,IAAlBkC,EAAiB,uDAAH,EAAG,yBAHnClC,UAGmC,OAFnCkC,SAEmC,EACvC3B,KAAKP,KAAOA,EACZO,KAAK2B,IAAMA,E,iDAGVA,GAAe3B,KAAK2B,IAAMA,I,8BAEb,OAAO3B,KAAK2B,M,4BACxBd,GAAuB,OAAQA,IAAMb,KAAQ,EAAI,I,8BAErC,OAAOA,KAAKP,S,KCb5BmC,E,oLAEE,OAAO5B,KAAKsB,KAAK5B,QAAUM,KAAKuB,MAAM7B,U,gCAGtBmB,GAGhB,OAFYb,KAAKsB,KAAKO,MAAMhB,GAAKb,KAAKuB,MAAM7B,QAChCM,KAAKsB,KAAK5B,QAAUM,KAAKuB,MAAMM,MAAMhB,K,8BAKjD,OAAOb,KAAKsB,KAAKQ,QAAU,MAAQ9B,KAAKuB,MAAMO,Y,GAZ7BT,GAgBnBU,E,oLAEE,OAAO/B,KAAKyB,MAAMO,QAAO,SAACC,EAAKC,GAAN,OAAYD,EAAMC,EAAExC,UAAS,K,gCAGtCmB,GAChB,OAAOb,KAAKyB,MAAMO,QAAO,SAACC,EAAKC,GAAN,OAAYD,EAAMC,EAAEL,MAAMhB,KAAI,K,8BAIvD,MAAO,IAAMb,KAAKyB,MAAM/C,KAAI,SAACwD,GAAD,OAAOA,EAAEJ,WAASK,KAAK,OAAS,Q,GAV/CX,GCfNY,E,WAGX,aAAe,yBAFPC,iBAEM,EACVrC,KAAKqC,YAAc,G,oDAIL,OAAOrC,KAAKiB,MAAMvB,U,8BAClB,OAAOM,KAAKiB,MAAMa,U,4BAI9BQ,GACFtC,KAAKqC,YAAYE,MAAMvC,KAAKwC,UAAUF,M,4BAIpCxC,GACF,GAAIE,KAAKqC,YAAYI,OAAS,EAAG,CAC7B,IAAMC,EAAa1C,KAAKqC,YAAYL,QAChC,SAACC,EAAKC,GAAN,OAAYD,EAAMC,IAAG,GACrBpC,EAAcE,KAAKqC,YAAYI,OACnCzC,KAAK2C,UAAUD,GACf1C,KAAKqC,YAAc,Q,KAMzBO,E,YAMF,WAAYC,GAAY,IAAD,8BACnB,+CAJIC,OAGe,IAFfZ,OAEe,EAEnB,EAAKY,EAAI,IAAIpB,EAAS,IAAMkB,EAAOG,MAAO,GAC1C,EAAKb,EAAI,IAAIN,EAAW,EAAKkB,EAAGD,EAAE5B,SAChC2B,EAAOG,MAJU,E,mEAOL,OAAO/C,KAAK8C,I,gCACF,OAAO9C,KAAKkC,I,gCAEpBI,GAChB,OAAOA,EAAMT,MAAM7B,KAAK8C,K,gCAERJ,GAChB1C,KAAK8C,EAAEE,KAAKhD,KAAKN,QAAUgD,K,8BAI3B1C,KAAKkC,EAAEe,Y,GAxBMb,GAAfQ,EACaG,MAAgB,E,IA2B7BG,E,YAKF,aAAe,IAAD,8BACV,+CAHIpE,OAEM,EAEV,EAAKA,EAAI,IAAI4C,EAAS,IAAMwB,EAAKH,MAAO,KACtCG,EAAKH,MAHG,E,mEAMI,OAAO/C,KAAKlB,I,gCACF,OAAOkB,KAAKiB,Q,gCAEpBqB,GAChB,OAAOA,EAAMT,MAAM7B,KAAKlB,K,gCAER4D,GAChB1C,KAAKlB,EAAEkE,KAAKhD,KAAKN,QAAUgD,O,GAlBhBN,GAAbc,EACKH,MAAgB,E,ICpDZI,E,gGAEO,OAAOnD,KAAKiB,MAAMvB,U,8BAClB,OAAOM,KAAKiB,MAAMa,Y,KAGlCsB,E,YAGF,WAAY3D,GAAe,IAAD,8BACtB,+CAHI4D,OAEkB,EAEtB,EAAKA,EAAI,IAAI3B,EAASjC,GAFA,E,mEAKF,OAAOO,KAAKqD,I,2BAE/B1B,GAAe3B,KAAKqD,EAAEL,KAAKrB,O,GAVVwB,GAaXG,E,YAMX,WAAYC,GAA6C,IAAD,uBACpD,+CANIC,aAKgD,IAJhDC,UAIgD,IAHhDC,SAGgD,IAFhDC,SAEgD,6BAAnBC,EAAmB,iCAAnBA,EAAmB,kBAEpD,EAAKJ,QAAUI,EAAQlF,KAAI,SAACmF,GAAD,OAAO,IAAIjB,EAAOiB,MAC7C,EAAKJ,KAAO,IAAIP,EAEhB,IAAMzB,EAAQ,EAAK+B,QAAQ9E,KAAI,SAACoF,GAAD,OAAOA,EAAEC,aALY,OAMpD,EAAKL,IAAL,YAAe3B,EAAf,YAAyBN,GAAzB,QAAgC,EAAKgC,KAAKM,aAC1C,EAAKJ,IAAM,IAAIJ,EAAI,EAAKG,KAP4B,E,mEAUhC,OAAO1D,KAAK2D,M,gCAC1BK,GAA+B,OAAOhE,KAAKwD,QAAQQ,K,gCAC3C,OAAOhE,KAAKyD,O,4BAExBnB,GACFtC,KAAKwD,QAAQS,SAAQ,SAACnB,GAAD,OAAOA,EAAEoB,MAAM5B,MACpCtC,KAAKyD,KAAKS,MAAM5B,K,4BAEdxC,GACFE,KAAKwD,QAAQS,SAAQ,SAACnB,GAAD,OAAOA,EAAEqB,MAAMrE,MACpCE,KAAKyD,KAAKU,MAAMrE,K,8BAIhBE,KAAK2D,IAAIV,QACTjD,KAAK0D,IAAIT,QACTjD,KAAKwD,QAAQS,SAAQ,SAACnB,GAAD,OAAOA,EAAEG,e,GAhCCE,GAoCjCiB,E,sIAAqBd,GAErBe,E,YAIF,WACI5E,EACA8D,EACAe,GAED,IAAD,mDADKV,EACL,iCADKA,EACL,yBACE,yDAAML,GAAN,OAAcK,MATVW,OAQN,IAPMC,SAON,EAEE,EAAKD,EAAI,IAAI7C,EAASjC,GACtB,EAAK+E,IAAM,IAAIF,EAAI,EAAKrD,MAAO,EAAKsD,GAHtC,E,sEAMyB,OAAOvE,KAAKwE,M,iCAClB,OAAOxE,KAAKyE,SAAS/E,U,iCACrB,OAAOM,KAAKyE,SAAS3C,U,2BAErCH,GAAe3B,KAAKuE,EAAEvB,KAAKrB,K,8BAG5B,8DACA3B,KAAKwE,IAAIvB,Y,GAvBUK,GC1DZoB,E,gGAGP,MAAO,IAAM1E,KAAKiB,MAAMvC,KAAI,SAACmE,GAAD,OAAOA,EAAEf,WAASK,KAAK,MAAQ,M,6BAG9C,OAAOnC,KAAKiB,MAAMwB,W,KAGjCkC,E,YAGF,aAAiC,IAAD,uBAC5B,+CAHIf,aAEwB,EAE5B,EAAKA,QAAU,IAAIjD,IAFS,2BAAjBiE,EAAiB,yBAAjBA,EAAiB,gBAG5B,cAAmBA,EAAnB,eAA0B,CAArB,IAAMnF,EAAI,KACX,EAAKmE,QAAQ7C,IAAItB,EAAM,IAAI2D,EAAY3D,IAJf,S,mEAQd,OAAOoF,MAAMC,KAAK9E,KAAK4D,QAAQmB,Y,gCACvCtF,GACN,OAAOO,KAAK4D,QAAQ3C,IAAIxB,K,+BAIxB,IAAIf,EAAM,IAAIiC,IADY,uBAE1B,YAA2BX,KAAK4D,QAAhC,+CAAyC,CAAC,IAAD,6BAA7BnE,EAA6B,KAAvBuF,EAAuB,KACrCtG,EAAIqC,IAAItB,EAAMuF,EAAKtF,UAHG,kFAK1B,OAAOhB,I,2BAGNuG,GAA4B,IAAD,uBAC5B,YAA6BjF,KAAK4D,QAAlC,+CAA2C,CAAC,IAAD,+BAA/BnE,EAA+B,UAChCuD,KAAP,UAAYiC,EAAKhE,IAAIxB,UAArB,QAA8B,IAFN,uF,GAxBXiF,GA+BVQ,E,8KAGL5C,GACFtC,KAAKiB,MAAMgD,SAAQ,SAACpB,GAAD,OAAOA,EAAEqB,MAAM5B,Q,4BAEhCxC,GACFE,KAAKiB,MAAMgD,SAAQ,SAACpB,GAAD,OAAOA,EAAEsB,MAAMrE,Q,8BAIlCE,KAAKiB,MAAMgD,SAAQ,SAACpB,GAAD,OAAOA,EAAEI,e,GAXEyB,GAehCS,E,YAGF,WAAYC,EAAe7B,EAAsB8B,GAAe,IAAD,uBAC3D,+CAHIzB,aAEuD,EAE3D,EAAKA,QAAU,GACf,IAAK,IAAI0B,EAAI,EAAGA,EAAID,IAAQC,EACxB,EAAK1B,QAAQrB,KAAb,YAAsB6B,EAAtB,CAAmCb,GAAnC,mBAA2C6B,EAAOnE,UAJK,S,mEAQpC,OAAOjB,KAAK4D,U,gCAC7BhF,GACN,OAAOoB,KAAK4D,QAAQhF,K,gCAGd2G,EAAoBvB,GAC1B,OAAOhE,KAAK4D,QAAQ2B,GAAYC,UAAUxB,K,8BAEtCuB,GACJ,OAAOvF,KAAK4D,QAAQ2B,GAAYE,Y,+BAGf,OAAOzF,KAAK4D,QAAQlF,KAAI,SAACmE,GAAD,OAAOA,EAAEnD,e,GAvBhCwF,GA0BpBQ,E,YAIF,WACIN,EACA7B,EACAe,GAED,IAAD,uBACE,+CATIV,aAQN,IAPMY,SAON,EAEE,EAAKZ,QAAU,IAAIjD,IAFrB,2BADKiE,EACL,iCADKA,EACL,kBAGE,cAAmBA,EAAnB,eAA0B,CAArB,IAAMnF,EAAI,KACX,EAAKmE,QAAQ7C,IACTtB,EADJ,YAEQ4E,EAFR,CAEqB5E,EAAM8D,EAAKe,GAFhC,mBAEwCc,EAAOnE,UANrD,OASE,EAAKuD,IAAL,YAAezC,EAAf,YACO8C,MAAMC,KAAK,EAAKlB,QAAQmB,UAAUrG,KAAI,SAACmE,GAAD,OAAOA,EAAE4B,cAVxD,E,mEAcyB,OAAOI,MAAMC,KAAK9E,KAAK4D,QAAQmB,Y,gCAChDtF,GACN,OAAOO,KAAK4D,QAAQ3C,IAAIxB,K,gCAGlBkG,EAAmB3B,GAA0C,IAAD,EAClE,iBAAOhE,KAAK4D,QAAQ3C,IAAI0E,UAAxB,aAAO,EAA6BH,UAAUxB,K,8BAE1CvE,GAAiC,IAAD,EACpC,iBAAOO,KAAK4D,QAAQ3C,IAAIxB,UAAxB,aAAO,EAAwBgG,Y,+BAGR,OAAOzF,KAAKwE,M,iCAClB,OAAOxE,KAAKyE,SAAS/E,U,iCACrB,OAAOM,KAAKyE,SAAS3C,U,+BAGtC,IAAIpD,EAAM,IAAIiC,IADY,uBAE1B,YAA2BX,KAAK4D,QAAhC,+CAAyC,CAAC,IAAD,6BAA7BnE,EAA6B,KAAvBuF,EAAuB,KACrCtG,EAAIqC,IAAItB,EAAMuF,EAAKtF,UAHG,kFAK1B,OAAOhB,I,2BAGNuG,GAA4B,IAAD,uBAC5B,YAA6BjF,KAAK4D,QAAlC,+CAA2C,CAAC,IAAD,+BAA/BnE,EAA+B,UAChCuD,KAAP,UAAYiC,EAAKhE,IAAIxB,UAArB,QAA8B,IAFN,qF,8BAO5B,8DACAO,KAAKwE,IAAIvB,Y,GAvDSiC,GCvBXU,E,WAnDX,aAAe,yBATPC,gBASM,OARNC,kBAQM,OAPNC,iBAOM,QACgB/F,KAAKgG,SAAvBC,EADE,EACFA,MAAOC,EADL,EACKA,OACTC,EAAatB,MAAMC,KAAKmB,EAAMG,QAC9BC,EAAcxB,MAAMC,KAAKoB,EAAOE,QAEtCpG,KAAK6F,WAAL,YAAsBlB,EAAtB,YAAoCwB,IACpCnG,KAAK8F,aAAe,GACpB,IAAIQ,EAActG,KAAK6F,WAPb,uBAQV,YAAmB7F,KAAKuG,cAAxB,+CAAuC,CAAC,IAA7BlB,EAA4B,QACnCrF,KAAK8F,aAAavD,KAAK,IAAI4C,EAAYmB,EAAMtG,KAAKuD,MAAO8B,IACzDiB,EAAOtG,KAAK8F,aAAa9F,KAAK8F,aAAarD,OAAS,IAV9C,kFAYVzC,KAAK+F,YAAL,YAAuBL,EAAvB,CACIY,EACAtG,KAAKuD,MACLvD,KAAKsE,OAHT,mBAIO+B,K,4DAImB,OAAOrG,KAAK6F,a,qCAC3BP,GAA0B,OAAOtF,KAAK8F,aAAaR,K,uCAClC,OAAOtF,KAAK+F,c,+BACjB,OAAO/F,KAAK+F,YAAYtB,W,gCAEzCwB,GAGN,OAFAjG,KAAKiD,QACLjD,KAAK6F,WAAW7C,KAAKiD,GACdjG,KAAK+F,YAAYhB,W,8BAIxB/E,KAAKiD,QADD,MAEsBjD,KAAKgG,SAAvBC,EAFJ,EAEIA,MAAOC,EAFX,EAEWA,OACflG,KAAK6F,WAAW7C,KAAKiD,GACrBjG,KAAK+F,YAAY/C,KAAKkD,GACtB,IAAM1B,EAAMxE,KAAK+F,YAAYtB,SAC7BzE,KAAK8F,aAAa7B,SAAQ,SAACuC,GAAD,OAAWA,EAAMtC,MAAMM,MACjDxE,KAAK+F,YAAY7B,MAAMM,K,4BAErB1E,GACFE,KAAK8F,aAAa7B,SAAQ,SAACuC,GAAD,OAAWA,EAAMrC,MAAMrE,MACjDE,KAAK+F,YAAY5B,MAAMrE,K,8BAIvBE,KAAK8F,aAAa7B,SAAQ,SAACuC,GAAD,OAAWA,EAAMvD,WAC3CjD,KAAK+F,YAAY9C,Y,KC5CnBwD,E,oLAEE,IAAIpD,EAAIrD,KAAKoB,IAAI1B,QACb6E,EAAI,EAAImC,KAAK/C,IAAIN,GACrB,OAAOnD,SAASqE,GAAKmC,KAAKC,IAAIpC,GAAKlB,I,gCAGnBxC,GAChB,IAAIwC,EAAIrD,KAAKoB,IAAI1B,QACbkH,EAAK,GAAK,EAAIF,KAAK/C,KAAKN,IAE5B,OADAuD,EAAK1G,SAAS0G,GAAMA,EAAK,GACb5G,KAAKoB,IAAIS,MAAMhB,K,8BAI3B,MAAO,QAAUb,KAAKoB,IAAIU,QAAU,Q,GAfXX,GClB3B0F,E,oLAEE,IAAIC,EAAO9G,KAAKsB,KAAK5B,QAAUM,KAAKuB,MAAM7B,QAC1C,OAAOoH,EAAOA,I,gCAGEjG,GAEhB,OAAO,GADIb,KAAKsB,KAAK5B,QAAUM,KAAKuB,MAAM7B,UACvBM,KAAKsB,KAAKO,MAAMhB,GAAKb,KAAKuB,MAAMM,MAAMhB,M,8BAIzD,MAAO,IAAMb,KAAKsB,KAAKQ,QAAU,MAAQ9B,KAAKuB,MAAM7B,QAAU,U,GAZ3C2B,GC2BZ0F,E,iLAzBP,MAAO,CACHd,MAAO,IAAItF,IAAoB,CAAC,CAAC,IAAK+F,KAAKM,YAC3Cd,OAAQ,IAAIvF,IAAoB,CAAC,CAAC,IAAK,S,4BAG7B,OAAOsG,I,4BACP,OAAOA,I,oCACC,MAAO,K,0BAK7B,OAAOjH,KAAKkH,iBAAiB1B,UAAU,IAAK,GAAI9F,U,0BAGhD,OAAOM,KAAKkH,iBAAiBzB,QAAQ,KAAM/F,U,4BAG3C,OAAOM,KAAKyE,SAAS/E,U,4BAEnB2D,GACF,OAAOrD,KAAKmH,UAAU,IAAIxG,IAAoB,CAAC,CAAC,IAAK0C,MAAMpC,IAAI,S,GAvB/CgG,GCoFTG,E,YA5EX,WAAY7I,GAAY,IAAD,8BACnB,4CAAMA,KALV8I,SAIuB,IAFvBjI,WAEuB,IAoBvBE,aAAe,SAACC,GAAmD,IAAD,EACtCA,EAAMC,OAAtBC,EADsD,EACtDA,KAAMC,EADgD,EAChDA,MACd,EAAKC,SAAL,eAAiBF,EAAOC,KAtBL,EAyBvBL,aAAe,SAACD,GACZ,IAAK,IAAIkG,EAAY,EAAGA,EAAIlG,EAAMW,cAAeuF,EAC7C,EAAKgC,MAAMlI,EAAMS,QAAST,EAAMU,cAxBpC,EAAKuH,IAAM,IAAIN,EACf,EAAK3H,MAAQ,CAAEX,KAAM,CAAC,CAAEI,EAAG,EAAGC,EAAG,EAAGC,OAAGwI,IAActB,MAAO,GAJzC,E,mEAOjBpG,EAAiBC,GAEnB,IADA,IAAI0H,EAAM,EACDlC,EAAI,EAAGA,EAAIzF,IAAWyF,EAC3BtF,KAAKqH,IAAInD,QACTsD,GAAOxH,KAAKqH,IAAIG,MAJoB,IAMlC/I,EAASuB,KAAKZ,MAAdX,KACNA,EAAKA,EAAKgE,OAAS,GAAG1D,EAAI2H,KAAKe,KAAKD,EAAM3H,GAC1CG,KAAKqH,IAAIlD,MAAMrE,GACfrB,EAAK8D,KAAK,CAAE1D,EAAGmB,KAAKqH,IAAIxI,IAAKC,EAAGkB,KAAKqH,IAAIvI,IAAKC,OAAGwI,IACjDvH,KAAKL,SAAS,CAAElB,KAAMA,M,+BAchB,IAAD,EACmBuB,KAAKZ,MAArBX,EADH,EACGA,KAAMwH,EADT,EACSA,MAEVC,EAAiBzF,IAKrB,OAJIP,SAAS+F,KACTC,EAASlG,KAAKqH,IAAI3H,MAAMuG,IAI1B,yBAAKyB,UAAU,aACb,qCACA,+HAAoG,6BAApG,2GACwG,6BADxG,0HAEuH,6BAFvH,oGAGiG,6BAHjG,wHAMA,uCACA,oIACA,wCACA,2BACEzH,KAAK,SACLR,KAAK,QACLC,MAAOuG,EACP7F,SAAUJ,KAAKV,eACjB,6BACA,yCACA,2BAAOqI,UAAQ,EACb1H,KAAK,OACLR,KAAK,SACLC,MAAOwG,IAET,wCACA,wGAA6E,6BAA7E,uIACoI,6BADpI,mGAEgG,6BAFhG,2FAGwF,6BAHxF,wIAKA,kBAAC,EAAD,CAAM7G,aAAcW,KAAKX,eACzB,kBAAC,EAAD,CAAOZ,KAAMA,S,GA3ED6B,aCqBTsH,MAjBf,WACI,OACE,kBAAC,IAAD,KACE,6BACE,6BACE,kBAAC,IAAD,CAAMC,GAAG,KAAI,4CAGjB,kBAAC,IAAD,KACE,kBAAC,IAAD,CAAOC,KAAK,KACV,kBAAC,EAAD,UCfZC,IAASC,OAAO,kBAAC,EAAD,MAASC,SAASC,eAAe,W","file":"static/js/main.8f9efa3e.chunk.js","sourcesContent":["import React from \"react\";\r\n\r\nexport type TableRow = {\r\n    m: number | undefined;\r\n    b: number | undefined;\r\n    r: number | undefined;\r\n};\r\n\r\nfunction TableHeader(): JSX.Element {\r\n    return (\r\n      <thead>\r\n        <tr>\r\n          <th>G</th>\r\n          <th>m</th>\r\n          <th>b</th>\r\n          <th>R</th>\r\n        </tr>\r\n      </thead>\r\n    );\r\n}\r\n\r\nfunction TableBody(props: { data: TableRow[] }): JSX.Element {\r\n    const rows = props.data.map((row: TableRow, index: number) => {\r\n        const { m, b, r } = row;\r\n        return (\r\n          <tr key={index}>\r\n            <td>{index}</td>\r\n            <td>{m ?? \"\"}</td>\r\n            <td>{b ?? \"\"}</td>\r\n            <td>{r ?? \"\"}</td>\r\n          </tr>\r\n        )\r\n    }).reverse();\r\n    return (\r\n        <tbody>{rows}</tbody>\r\n    );\r\n}\r\n\r\nfunction Table(props: { data: TableRow[] }) {\r\n    const { data } = props;\r\n    return (\r\n      <table>\r\n        <TableHeader />\r\n        <TableBody data={data} />\r\n      </table>\r\n    );\r\n}\r\n\r\nexport default Table;\r\n","import React, { Component } from \"react\";\r\n\r\nexport type FormState = {\r\n    samples: number;\r\n    sensitivity: number;\r\n    generations: number;\r\n};\r\n\r\nexport type FormProps = {\r\n    handleSubmit: (state: FormState) => void;\r\n};\r\n\r\nclass Form extends Component<FormProps> {\r\n    state: FormState;\r\n    handleSubmit: (state: FormState) => void;\r\n\r\n    constructor(props: FormProps) {\r\n        super(props);\r\n        this.state = { samples: 1, sensitivity: 1, generations: 1 };\r\n        this.handleSubmit = (props as any).handleSubmit;\r\n    }\r\n\r\n    handleChange = (event: { target: { name: any; value: any; }; }) => {\r\n        const { name, value } = event.target;\r\n        this.setState({ [name]: value });\r\n    }\r\n\r\n    submitForm = () => {\r\n        (this.props as any).handleSubmit(this.state)\r\n    }\r\n\r\n    render() {\r\n        const { samples, sensitivity, generations } = this.state;\r\n        return (\r\n          <form>\r\n            <label>Samples</label>\r\n            <input\r\n              type=\"number\"\r\n              name=\"samples\"\r\n              value={isFinite(samples) ? samples : \"\"}\r\n              min=\"1\"\r\n              onChange={this.handleChange} />\r\n            <br />\r\n\r\n            <label>Sensitivity</label>\r\n            <input\r\n              type=\"number\"\r\n              name=\"sensitivity\"\r\n              value={isFinite(sensitivity) ? sensitivity : \"\"}\r\n              onChange={this.handleChange} />\r\n            <br />\r\n\r\n            <label>Generations</label>\r\n            <input\r\n              type=\"number\"\r\n              name=\"generations\"\r\n              value={isFinite(generations) ? generations : \"\"}\r\n              min=\"0\"\r\n              onChange={this.handleChange} />\r\n            <br />\r\n\r\n            <input type=\"button\" value=\"Train\" onClick={this.submitForm} />\r\n          </form>\r\n        );\r\n    }\r\n}\r\n\r\nexport default Form;\r\n","import Differentiable from \"./differentiable\";\r\nimport Variable from \"./variable\";\r\n\r\nabstract class Expression implements Differentiable {\r\n    private _value: number = NaN;\r\n    value(): number {\r\n        if (!isFinite(this._value)) {\r\n            this._value = this.valueImpl();\r\n        }\r\n        return this._value;\r\n    }\r\n    protected abstract valueImpl(): number;\r\n\r\n    private _deriv = new Map<Variable, number>();\r\n    deriv(v: Variable): number {\r\n        if (!this._deriv.has(v)) {\r\n            this._deriv.set(v, this.derivImpl(v));\r\n        }\r\n        return this._deriv.get(v) as number;\r\n    }\r\n    protected abstract derivImpl(_v: Variable): number;\r\n\r\n    abstract print(): string;\r\n\r\n    reset() {\r\n        this._value = NaN;\r\n        this._deriv.clear();\r\n    }\r\n}\r\n\r\nabstract class ExprUnary extends Expression {\r\n    protected arg: Differentiable;\r\n\r\n    constructor(arg: Differentiable) {\r\n        super();\r\n        this.arg = arg;\r\n    }\r\n}\r\n\r\nabstract class ExprBinary extends Expression {\r\n    protected left: Differentiable;\r\n    protected right: Differentiable;\r\n\r\n    constructor(left: Differentiable, right: Differentiable) {\r\n        super();\r\n        this.left = left;\r\n        this.right = right;\r\n    }\r\n}\r\n\r\nabstract class ExprVariadic extends Expression {\r\n    protected terms: Differentiable[];\r\n\r\n    constructor(...terms: Differentiable[]) {\r\n        super();\r\n        this.terms = terms;\r\n    }\r\n}\r\n\r\nexport default Expression;\r\nexport { ExprUnary, ExprBinary, ExprVariadic };\r\n","import Differentiable from \"./differentiable\";\r\n\r\nclass Variable implements Differentiable {\r\n    private name: string;\r\n    private val: number;\r\n\r\n    constructor(name: string, val: number = 0) {\r\n        this.name = name;\r\n        this.val = val;\r\n    }\r\n\r\n    bind(val: number) { this.val = val; }\r\n\r\n    value(): number { return this.val; }\r\n    deriv(v: Variable): number { return (v === this) ? 1 : 0; }\r\n\r\n    print(): string { return this.name; }\r\n}\r\n\r\nexport default Variable;\r\n","import { ExprBinary, ExprVariadic } from \"./expression\";\r\nimport Variable from \"./variable\";\r\n\r\nclass BinProduct extends ExprBinary {\r\n    protected valueImpl(): number {\r\n        return this.left.value() * this.right.value();\r\n    }\r\n\r\n    protected derivImpl(v: Variable): number {\r\n        const dlr = this.left.deriv(v) * this.right.value();\r\n        const ldr = this.left.value() * this.right.deriv(v);\r\n        return dlr + ldr;\r\n    }\r\n\r\n    print(): string {\r\n        return this.left.print() + \" * \" + this.right.print();\r\n    }\r\n}\r\n\r\nclass VarSum extends ExprVariadic {\r\n    protected valueImpl(): number {\r\n        return this.terms.reduce((acc, t) => acc + t.value(), 0);\r\n    }\r\n\r\n    protected derivImpl(v: Variable): number {\r\n        return this.terms.reduce((acc, t) => acc + t.deriv(v), 0);\r\n    }\r\n\r\n    print(): string {\r\n        return \"(\" + this.terms.map((t) => t.print()).join(\" + \") + \")\";\r\n    }\r\n}\r\n\r\nexport { BinProduct, VarSum };\r\n","import { Differentiable, Variable, BinProduct } from \"../diffable/diffable\";\r\nimport Trainable from \"./trainable\";\r\nimport Neuron from \"./neurons\";\r\n\r\nabstract class Parameter implements Trainable {\r\n    private adjustments: number[];\r\n\r\n    constructor() {\r\n        this.adjustments = [];\r\n    }\r\n\r\n    abstract get(): Variable;\r\n    value(): number { return this.get().value(); }\r\n    print(): string { return this.get().print(); }\r\n\r\n    abstract getExpr(): Differentiable;\r\n\r\n    study(error: Differentiable) {\r\n        this.adjustments.push(-this.studyImpl(error));\r\n    }\r\n    protected abstract studyImpl(error: Differentiable): number;\r\n\r\n    learn(sensitivity: number) {\r\n        if (this.adjustments.length > 0) {\r\n            const adjustment = this.adjustments.reduce(\r\n                (acc, t) => acc + t, 0\r\n            ) * sensitivity / this.adjustments.length;\r\n            this.learnImpl(adjustment);\r\n            this.adjustments = [];\r\n        }\r\n    }\r\n    protected abstract learnImpl(adjustment: number): void;\r\n}\r\n\r\nclass Weight extends Parameter {\r\n    private static count: number = 0;\r\n\r\n    private w: Variable;\r\n    private t: BinProduct;\r\n\r\n    constructor(n: Neuron) {\r\n        super();\r\n        this.w = new Variable(\"w\" + Weight.count, 1);\r\n        this.t = new BinProduct(this.w, n.get());\r\n        ++Weight.count;\r\n    }\r\n\r\n    get(): Variable { return this.w; }\r\n    getExpr(): Differentiable { return this.t; }\r\n\r\n    protected studyImpl(error: Differentiable): number {\r\n        return error.deriv(this.w);\r\n    }\r\n    protected learnImpl(adjustment: number) {\r\n        this.w.bind(this.value() + adjustment);\r\n    }\r\n\r\n    reset() {\r\n        this.t.reset();\r\n    }\r\n}\r\n\r\nclass Bias extends Parameter {\r\n    static count: number = 0;\r\n\r\n    private b: Variable;\r\n\r\n    constructor() {\r\n        super();\r\n        this.b = new Variable(\"b\" + Bias.count, 0);\r\n        ++Bias.count;\r\n    }\r\n\r\n    get(): Variable { return this.b; }\r\n    getExpr(): Differentiable { return this.get(); }\r\n\r\n    protected studyImpl(error: Differentiable): number {\r\n        return error.deriv(this.b);\r\n    }\r\n    protected learnImpl(adjustment: number) {\r\n        this.b.bind(this.value() + adjustment);\r\n    }\r\n}\r\n\r\nexport { Weight, Bias };\r\n","import {\r\n    Differentiable,\r\n    ExprUnary, ExprBinary,\r\n    Variable,\r\n    VarSum\r\n} from \"../diffable/diffable\";\r\nimport Trainable from \"./trainable\";\r\nimport { Weight, Bias } from \"./parameters\";\r\nimport { ActivationClass } from \"./activation\";\r\nimport { ErrorClass } from \"./error\";\r\n\r\nabstract class Neuron {\r\n    abstract get(): Differentiable;\r\n    value(): number { return this.get().value(); }\r\n    print(): string { return this.get().print(); }\r\n}\r\n\r\nclass InputNeuron extends Neuron {\r\n    private x: Variable;\r\n\r\n    constructor(name: string) {\r\n        super();\r\n        this.x = new Variable(name);\r\n    }\r\n\r\n    get(): Differentiable { return this.x; }\r\n\r\n    bind(val: number) { this.x.bind(val); }\r\n}\r\n\r\nabstract class TrainableNeuron extends Neuron implements Trainable {\r\n    private weights: Weight[];\r\n    private bias: Bias;\r\n    private sum: VarSum;\r\n    private exp: ExprUnary;\r\n\r\n    constructor(Act: ActivationClass, ...neurons: Neuron[]) {\r\n        super();\r\n        this.weights = neurons.map((p) => new Weight(p));\r\n        this.bias = new Bias();\r\n\r\n        const terms = this.weights.map((c) => c.getExpr());\r\n        this.sum = new VarSum(...terms, this.bias.getExpr());\r\n        this.exp = new Act(this.sum);\r\n    }\r\n\r\n    get(): Differentiable { return this.exp; }\r\n    getWeight(parentIndex: number): Weight { return this.weights[parentIndex]; }\r\n    getBias(): Bias { return this.bias; }\r\n\r\n    study(error: Differentiable) {\r\n        this.weights.forEach((w) => w.study(error));\r\n        this.bias.study(error);\r\n    }\r\n    learn(sensitivity: number) {\r\n        this.weights.forEach((w) => w.learn(sensitivity));\r\n        this.bias.learn(sensitivity);\r\n    }\r\n\r\n    reset() {\r\n        this.exp.reset();\r\n        this.sum.reset();\r\n        this.weights.forEach((w) => w.reset());\r\n    }\r\n}\r\n\r\nclass HiddenNeuron extends TrainableNeuron {}\r\n\r\nclass OutputNeuron extends TrainableNeuron {\r\n    private y: Variable;\r\n    private err: ExprBinary;\r\n\r\n    constructor(\r\n        name: string,\r\n        Act: ActivationClass,\r\n        Err: ErrorClass,\r\n        ...neurons: Neuron[]\r\n    ) {\r\n        super(Act, ...neurons);\r\n        this.y = new Variable(name);\r\n        this.err = new Err(this.get(), this.y);\r\n    }\r\n\r\n    getErr(): Differentiable { return this.err; }\r\n    valueErr(): number { return this.getErr().value(); }\r\n    printErr(): string { return this.getErr().print(); }\r\n\r\n    bind(val: number) { this.y.bind(val); }\r\n\r\n    reset() {\r\n        super.reset();\r\n        this.err.reset();\r\n    }\r\n}\r\n\r\nexport default Neuron;\r\nexport { InputNeuron, TrainableNeuron, HiddenNeuron, OutputNeuron };\r\n","import Neuron, {\r\n    InputNeuron,\r\n    TrainableNeuron, HiddenNeuron, OutputNeuron\r\n} from \"./neurons\";\r\nimport { Differentiable, VarSum } from \"../diffable/diffable\";\r\nimport { ActivationClass } from \"./activation\";\r\nimport { ErrorClass } from \"./error\";\r\nimport { Weight, Bias } from \"./parameters\";\r\nimport Trainable from \"./trainable\";\r\n\r\nabstract class Layer {\r\n    abstract get(): Neuron[];\r\n    print(): string {\r\n        return \"[\" + this.get().map((n) => n.print()).join(\", \") + \"]\";\r\n    }\r\n\r\n    size(): number { return this.get().length; }\r\n}\r\n\r\nclass InputLayer extends Layer {\r\n    private neurons: Map<string, InputNeuron>;\r\n\r\n    constructor(...names: string[]) {\r\n        super();\r\n        this.neurons = new Map();\r\n        for (const name of names) {\r\n            this.neurons.set(name, new InputNeuron(name));\r\n        }\r\n    }\r\n\r\n    get(): Neuron[] { return Array.from(this.neurons.values()); }\r\n    getNeuron(name: string): Neuron | undefined {\r\n        return this.neurons.get(name);\r\n    }\r\n\r\n    values(): Map<string, number> {\r\n        let map = new Map<string, number>();\r\n        for (const [name, node] of this.neurons) {\r\n            map.set(name, node.value());\r\n        }\r\n        return map;\r\n    }\r\n\r\n    bind(vals: Map<string, number>) {\r\n        for (const [name, neuron] of this.neurons) {\r\n            neuron.bind(vals.get(name) ?? 0);\r\n        }\r\n    }\r\n}\r\n\r\nabstract class TrainableLayer extends Layer implements Trainable {\r\n    abstract get(): TrainableNeuron[];\r\n\r\n    study(error: Differentiable) {\r\n        this.get().forEach((n) => n.study(error));\r\n    }\r\n    learn(sensitivity: number) {\r\n        this.get().forEach((n) => n.learn(sensitivity));\r\n    }\r\n\r\n    reset() {\r\n        this.get().forEach((n) => n.reset());\r\n    }\r\n}\r\n\r\nclass HiddenLayer extends TrainableLayer {\r\n    private neurons: TrainableNeuron[];\r\n\r\n    constructor(parent: Layer, Act: ActivationClass, size: number) {\r\n        super();\r\n        this.neurons = [];\r\n        for (let i = 0; i < size; ++i) {\r\n            this.neurons.push(new HiddenNeuron(Act, ...parent.get()))\r\n        }\r\n    }\r\n\r\n    get(): TrainableNeuron[] { return this.neurons; }\r\n    getNeuron(index: number): Neuron {\r\n        return this.neurons[index];\r\n    }\r\n\r\n    getWeight(childIndex: number, parentIndex: number): Weight {\r\n        return this.neurons[childIndex].getWeight(parentIndex);\r\n    }\r\n    getBias(childIndex: number): Bias {\r\n        return this.neurons[childIndex].getBias();\r\n    }\r\n\r\n    values(): number[] { return this.neurons.map((n) => n.value())};\r\n}\r\n\r\nclass OutputLayer extends TrainableLayer {\r\n    private neurons: Map<string, OutputNeuron>;\r\n    private err: VarSum;\r\n\r\n    constructor(\r\n        parent: Layer,\r\n        Act: ActivationClass,\r\n        Err: ErrorClass,\r\n        ...names: string[]\r\n    ) {\r\n        super();\r\n        this.neurons = new Map();\r\n        for (const name of names) {\r\n            this.neurons.set(\r\n                name,\r\n                new OutputNeuron(name, Act, Err, ...parent.get())\r\n            );\r\n        }\r\n        this.err = new VarSum(\r\n            ...Array.from(this.neurons.values()).map((n) => n.getErr())\r\n        );\r\n    }\r\n\r\n    get(): TrainableNeuron[] { return Array.from(this.neurons.values()); }\r\n    getNeuron(name: string): Neuron | undefined {\r\n        return this.neurons.get(name);\r\n    }\r\n\r\n    getWeight(childName: string, parentIndex: number): Weight | undefined {\r\n        return this.neurons.get(childName)?.getWeight(parentIndex);\r\n    }\r\n    getBias(name: string): Bias | undefined {\r\n        return this.neurons.get(name)?.getBias();\r\n    }\r\n\r\n    getErr(): Differentiable { return this.err; }\r\n    valueErr(): number { return this.getErr().value(); }\r\n    printErr(): string { return this.getErr().print(); }\r\n\r\n    values(): Map<string, number> {\r\n        let map = new Map<string, number>();\r\n        for (const [name, node] of this.neurons) {\r\n            map.set(name, node.value());\r\n        }\r\n        return map;\r\n    }\r\n\r\n    bind(vals: Map<string, number>) {\r\n        for (const [name, neuron] of this.neurons) {\r\n            neuron.bind(vals.get(name) ?? 0);\r\n        }\r\n    }\r\n\r\n    reset() {\r\n        super.reset();\r\n        this.err.reset();\r\n    }\r\n}\r\n\r\nexport default Layer;\r\nexport { InputLayer, HiddenLayer, OutputLayer };\r\n","import Layer, { InputLayer, HiddenLayer, OutputLayer } from \"./layers\";\r\nimport { ActivationClass } from \"./activation\";\r\nimport { ErrorClass } from \"./error\";\r\nimport Differentiable from \"../diffable/differentiable\";\r\n\r\ntype Sample = { input: Map<string, number>; output: Map<string, number>; };\r\n\r\nabstract class Network {\r\n    private inputLayer: InputLayer;\r\n    private hiddenLayers: HiddenLayer[];\r\n    private outputLayer: OutputLayer;\r\n\r\n    protected abstract source(): Sample;\r\n    protected abstract Act(): ActivationClass;\r\n    protected abstract Err(): ErrorClass;\r\n    protected abstract hiddenSizes(): number[];\r\n\r\n    constructor() {\r\n        const { input, output } = this.source();\r\n        const inputNames = Array.from(input.keys());\r\n        const outputNames = Array.from(output.keys());\r\n\r\n        this.inputLayer = new InputLayer(...inputNames);\r\n        this.hiddenLayers = [];\r\n        let last: Layer = this.inputLayer;\r\n        for (const size of this.hiddenSizes()) {\r\n            this.hiddenLayers.push(new HiddenLayer(last, this.Act(), size));\r\n            last = this.hiddenLayers[this.hiddenLayers.length - 1];\r\n        }\r\n        this.outputLayer = new OutputLayer(\r\n            last,\r\n            this.Act(),\r\n            this.Err(),\r\n            ...outputNames\r\n        );\r\n    }\r\n\r\n    getInputLayer(): InputLayer { return this.inputLayer; }\r\n    getHiddenLayer(i: number): HiddenLayer { return this.hiddenLayers[i]; }\r\n    getOutputLayer(): OutputLayer { return this.outputLayer; }\r\n    getErr(): Differentiable { return this.outputLayer.getErr(); }\r\n\r\n    getOutput(input: Map<string, number>): Map<string, number> {\r\n        this.reset();\r\n        this.inputLayer.bind(input);\r\n        return this.outputLayer.values();\r\n    }\r\n\r\n    study() {\r\n        this.reset();\r\n        const { input, output } = this.source();\r\n        this.inputLayer.bind(input);\r\n        this.outputLayer.bind(output);\r\n        const err = this.outputLayer.getErr();\r\n        this.hiddenLayers.forEach((layer) => layer.study(err));\r\n        this.outputLayer.study(err);\r\n    }\r\n    learn(sensitivity: number) {\r\n        this.hiddenLayers.forEach((layer) => layer.learn(sensitivity));\r\n        this.outputLayer.learn(sensitivity);\r\n    }\r\n\r\n    reset() {\r\n        this.hiddenLayers.forEach((layer) => layer.reset());\r\n        this.outputLayer.reset();\r\n    }\r\n}\r\n\r\nexport default Network;\r\n","import { Differentiable, ExprUnary, Variable } from \"../diffable/diffable\";\r\n\r\nclass ActivationLogistic extends ExprUnary {\r\n    protected valueImpl(): number {\r\n        let x = this.arg.value();\r\n        let y = 1 / (1 + Math.exp(-x));\r\n        return isFinite(y) ? y : ((x < 0) ? 0 : 1);\r\n    }\r\n\r\n    protected derivImpl(v: Variable): number {\r\n        let val = this.arg.value();\r\n        let d = this.arg.deriv(v) / (Math.exp(val) + 2 + Math.exp(-val));\r\n        return isFinite(d) ? d : 0;\r\n    }\r\n\r\n    print(): string {\r\n        return \"Ïƒ(\" + this.arg.print() + \")\";\r\n    }\r\n}\r\n\r\nclass ActivationSoftplus extends ExprUnary {\r\n    protected valueImpl(): number {\r\n        let x = this.arg.value();\r\n        let y = 1 + Math.exp(x);\r\n        return isFinite(y) ? Math.log(y) : x;\r\n    }\r\n\r\n    protected derivImpl(v: Variable): number {\r\n        let x = this.arg.value();\r\n        let df = 1 / (1 + Math.exp(-x));\r\n        df = isFinite(df) ? df : 0;\r\n        return df * this.arg.deriv(v);\r\n    }\r\n\r\n    print(): string {\r\n        return \"ReLU(\" + this.arg.print() + \")\";\r\n    }\r\n}\r\n\r\nexport interface ActivationClass {\r\n    new(arg: Differentiable): ExprUnary;\r\n}\r\nexport { ActivationLogistic, ActivationSoftplus };\r\n","import { Differentiable, ExprBinary, Variable } from \"../diffable/diffable\";\r\n\r\nclass ErrorSquared extends ExprBinary {\r\n    protected valueImpl(): number {\r\n        let diff = this.left.value() - this.right.value();\r\n        return diff * diff;\r\n    }\r\n\r\n    protected derivImpl(v: Variable): number {\r\n        let diff = this.left.value() - this.right.value();\r\n        return 2 * diff * (this.left.deriv(v) - this.right.deriv(v));\r\n    }\r\n\r\n    print(): string {\r\n        return \"(\" + this.left.print() + \" - \" + this.right.value() + \")^2\";\r\n    }\r\n}\r\n\r\nexport interface ErrorClass {\r\n    new(left: Differentiable, right: Differentiable): ExprBinary;\r\n}\r\nexport { ErrorSquared };\r\n","import * as Neuro from \"../neuro/neuro\";\r\n\r\nclass Network42 extends Neuro.Network {\r\n    protected source() {\r\n        return {\r\n            input: new Map<string, number>([['x', Math.random()]]),\r\n            output: new Map<string, number>([['y', 42]])\r\n        };\r\n    }\r\n    protected Act() { return Neuro.ActivationSoftplus; }\r\n    protected Err() { return Neuro.ErrorSquared; }\r\n    protected hiddenSizes() { return []; }\r\n\r\n    // Convenience Methods\r\n\r\n    m(): number {\r\n        return this.getOutputLayer().getWeight('y', 0)!.value();\r\n    }\r\n    b(): number {\r\n        return this.getOutputLayer().getBias('y')!.value();\r\n    }\r\n    rsq(): number {\r\n        return this.getErr().value();\r\n    }\r\n    value(x: number): number {\r\n        return this.getOutput(new Map<string, number>([['x', x]])).get('y')!;\r\n    }\r\n}\r\n\r\nexport default Network42;\r\n","import React, { Component } from \"react\";\r\nimport Table, { TableRow } from \"./Table\";\r\nimport Form, { FormState } from \"./Form\";\r\nimport Network42 from \"./Network42\";\r\n\r\nclass Asteria42 extends Component<{}> {\r\n    net: Network42;\r\n\r\n    state: { data: TableRow[]; input: number };\r\n\r\n    constructor(props: {}) {\r\n        super(props);\r\n\r\n        this.net = new Network42();\r\n        this.state = { data: [{ m: 1, b: 0, r: undefined }], input: 0 };\r\n    }\r\n\r\n    train(samples: number, sensitivity: number) {\r\n        let rsq = 0;\r\n        for (let i = 0; i < samples; ++i) {\r\n            this.net.study();\r\n            rsq += this.net.rsq();\r\n        }\r\n        let { data } = this.state;\r\n        data[data.length - 1].r = Math.sqrt(rsq / samples);\r\n        this.net.learn(sensitivity);\r\n        data.push({ m: this.net.m(), b: this.net.b(), r: undefined });\r\n        this.setState({ data: data });\r\n    }\r\n\r\n    handleChange = (event: { target: { name: any; value: any }; }) => {\r\n        const { name, value } = event.target;\r\n        this.setState({ [name]: value });\r\n    };\r\n\r\n    handleSubmit = (state: FormState) => {\r\n        for (let i: number = 0; i < state.generations; ++i) {\r\n            this.train(state.samples, state.sensitivity);\r\n        }\r\n    };\r\n\r\n    render() {\r\n        const { data, input } = this.state;\r\n\r\n        let output: number = NaN;\r\n        if (isFinite(input)) {\r\n            output = this.net.value(input);\r\n        }\r\n\r\n        return (\r\n          <div className=\"Asteria42\">\r\n            <h2>About</h2>\r\n            <p>Asteria wants to learn the answer to life, the universe, and everything, but she needs your help!<br />\r\n            Asteria is the simplest possible neural network: a single input neuron linked to a single output neuron.<br />\r\n            She has no hidden layers, so Asteria is really just a linear relation passed through an activation function (softplus).<br />\r\n            The full equation for Asteria is y=ReLU(mx+b). Her initial state is y=ReLU(x), where m=1 and b=0.<br />\r\n            Asteria will be trained to minimize R^2, the mean of (y-42)^2 over randomly-sampled values of x ranging from 0 to 1.</p>\r\n\r\n            <h2>Testing</h2>\r\n            <p>If she has learned well, Asteria should output 42 no matter what input we give her. Test it out here!</p>\r\n            <label>Input</label>\r\n            <input\r\n              type=\"number\"\r\n              name=\"input\"\r\n              value={input}\r\n              onChange={this.handleChange} />\r\n            <br />\r\n            <label>Output</label>\r\n            <input readOnly\r\n              type=\"text\"\r\n              name=\"output\"\r\n              value={output} />\r\n\r\n            <h2>Training</h2>\r\n            <p>We want Asteria to ultimately settle on y=42~ReLU(42), where m=0 and b=42.<br />\r\n            To determine how to adjust m and b, Asteria samples values of x between 0 to 1 (you decide how many) and does fancy backpropagation.<br />\r\n            Sensitivity determines the strength of the adjustments to m and b in each generation of Asteria.<br />\r\n            If sensitivity is negative, Asteria will try to maximize error instead of minimizing it.<br />\r\n            If sensitivity is too large (the upper bound is around 0.75), Asteria will overshoot on her adjustments and fail to settle anywhere.</p>\r\n            <Form handleSubmit={this.handleSubmit} />\r\n            <Table data={data} />\r\n          </div>\r\n        );\r\n    }\r\n}\r\n\r\nexport default Asteria42;\r\n","import React from \"react\";\r\nimport {\r\n    BrowserRouter as Router,\r\n    Switch,\r\n    Route,\r\n    Link\r\n} from \"react-router-dom\";\r\nimport Asteria42 from \"./asteria42/Asteria42\";\r\n\r\nfunction App() {\r\n    return (\r\n      <Router>\r\n        <div>\r\n          <nav>\r\n            <Link to=\"/\"><h1>Asteria42</h1></Link>\r\n\t\t\t\t\t</nav>\r\n\t\t\t\t</div>\r\n        <Switch>\r\n          <Route path=\"/\">\r\n            <Asteria42 />\r\n          </Route>\r\n        </Switch>\r\n\t\t\t</Router>\r\n    );\r\n}\r\n\r\nexport default App;\r\n","import React from \"react\";\nimport ReactDOM from \"react-dom\";\nimport App from \"./App\";\n\nReactDOM.render(<App />, document.getElementById(\"root\"));\n"],"sourceRoot":""}